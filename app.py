# app.py

import os
from dotenv import load_dotenv
import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from datasets import load_dataset # Veri oluÅŸturma iÃ§in gerekli
from langchain_core.documents import Document # Veri oluÅŸturma iÃ§in gerekli

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# Ayarlar
DB_PATH = "./chroma_db_banka_sss"
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
LLM_MODEL = "gemini-2.5-flash"

# --- KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K: VektÃ¶r VeritabanÄ± OluÅŸturma MantÄ±ÄŸÄ± ---
@st.cache_resource
def build_vector_database_on_demand(db_path, model_name):
    """
    VektÃ¶r veritabanÄ± mevcut deÄŸilse, build_vector_db.py'deki mantÄ±ÄŸÄ± kullanarak oluÅŸturur.
    Streamlit Cloud'da veritabanÄ±nÄ±n kaybolmasÄ± durumunu ele almak iÃ§in gereklidir.
    """
    # VeritabanÄ± mevcutsa ve saÄŸlam gÃ¶rÃ¼nÃ¼yorsa tekrar oluÅŸturma
    if os.path.exists(db_path) and os.path.exists(os.path.join(db_path, "chroma-collections.parquet")):
        # st.info("âœ… VektÃ¶r veritabanÄ± zaten mevcut. Tekrar oluÅŸturulmuyor.")
        return

    st.info("ğŸš¨ VektÃ¶r veritabanÄ± bulunamadÄ±. Otomatik olarak oluÅŸturuluyor...")
    
    # Veri YÃ¼kleme (build_vector_db.py'den kopyalanmÄ±ÅŸtÄ±r - sadece demo veri)
    dataset = [
        {'question': 'Kredi kartÄ± baÅŸvurusu nasÄ±l yapÄ±lÄ±r?', 'answer': 'Akbank mÃ¼ÅŸterisiyseniz Akbank Mobil ve Ä°nternet Ã¼zerinden, Akbank mÃ¼ÅŸterisi deÄŸilseniz Akbank Mobil\'i indirerek gÃ¶rÃ¼ntÃ¼lÃ¼ gÃ¶rÃ¼ÅŸme ile hÄ±zlÄ±ca baÅŸvuru yapabilirsiniz. AyrÄ±ca 444 25 25 MÃ¼ÅŸteri Ä°letiÅŸim Merkezi, Axess.com.tr ve tÃ¼m ÅŸubelerimizden de baÅŸvuru yapÄ±labilir.'},
        {'question': 'DÃ¶viz hesabÄ± aÃ§mak iÃ§in ne gerekiyor?', 'answer': 'Åubelerimizden veya mobil bankacÄ±lÄ±k Ã¼zerinden, kimlik belgenizle kolayca dÃ¶viz hesabÄ± aÃ§abilirsiniz. Ek bir belgeye gerek yoktur.'},
        {'question': 'Hesap iÅŸletim Ã¼creti alÄ±yor musunuz?', 'answer': 'Belirli ÅŸartlarÄ± saÄŸlayan mÃ¼ÅŸterilerimizden hesap iÅŸletim Ã¼creti alÄ±nmamaktadÄ±r. DetaylÄ± bilgi iÃ§in sÃ¶zleÅŸmenizi inceleyin.'},
        {'question': 'Åifremi nasÄ±l deÄŸiÅŸtirebilirim?', 'answer': 'Åifrenizi Akbank Mobil veya Akbank Ä°nternet Ã¼zerinden "Åifre Ä°ÅŸlemleri" menÃ¼sÃ¼nÃ¼ kullanarak anÄ±nda deÄŸiÅŸtirebilirsiniz.'},
        {'question': 'Akbank mobil ile hangi iÅŸlemleri yapabilirim?', 'answer': 'Mobil uygulama ile para transferi, fatura Ã¶demeleri, yatÄ±rÄ±m iÅŸlemleri ve yeni Ã¼rÃ¼n baÅŸvurularÄ± dahil birÃ§ok bankacÄ±lÄ±k iÅŸlemini ÅŸubeye gitmeden gerÃ§ekleÅŸtirebilirsiniz.'}
    ]
    
    documents = []
    for item in dataset:
        combined_content = f"Soru: {item['question']}\nCevap: {item['answer']}"
        doc = Document(
            page_content=combined_content,
            metadata={"source_question": item['question'], "source": "Demo Veri Seti"}
        )
        documents.append(doc)

    # Embedding modelini yÃ¼kle
    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={'device': 'cpu'}
    )

    # Chroma veritabanÄ± oluÅŸturma ve kalÄ±cÄ± hale getirme
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=db_path
    )
    vectorstore.persist()
    st.success("âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.")
    return

# --- load_rag_components fonksiyonu ---
@st.cache_resource
def load_rag_components():
    """RAG bileÅŸenlerini yÃ¼kler"""
    
    # âš ï¸ 1. Kontrol: VeritabanÄ±nÄ± oluÅŸtur veya varlÄ±ÄŸÄ±nÄ± kontrol et
    # Bu fonksiyon, Streamlit Cloud'da veritabanÄ±nÄ±n bulunamamasÄ± sorununu Ã§Ã¶zer.
    build_vector_database_on_demand(DB_PATH, EMBEDDING_MODEL_NAME)
    
    st.info("ğŸ§  RAG bileÅŸenleri yÃ¼kleniyor...")
    
    # Embedding modeli
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'}
    )
    
    # VektÃ¶r veritabanÄ±
    vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    # LLM Modeli
    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2)
    
    st.success("âœ… RAG BileÅŸenleri BaÅŸarÄ±yla YÃ¼klendi.")
    return retriever, llm

# Prompt template (AynÄ± kaldÄ±)
template = """Sen, bir bankanÄ±n mÃ¼ÅŸteri hizmetleri temsilcisisin. Sadece aÅŸaÄŸÄ±da verilen 'BaÄŸlam' iÃ§indeki bilgilere dayanarak soruyu yanÄ±tla. BaÄŸlamda cevabÄ± bulunmayan bir soru sorulursa, "Bu konuda bir bilgim bulunmuyor, lÃ¼tfen bankanÄ±zla doÄŸrudan iletiÅŸime geÃ§in." de.

BaÄŸlam:
{context}

KullanÄ±cÄ± Sorusu: {question}
"""
prompt = ChatPromptTemplate.from_template(template)

def create_rag_chain(retriever, llm):
    """RAG zinciri oluÅŸturur"""
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

# Streamlit uygulamasÄ±
st.set_page_config(page_title="Akbank Sanal Asistan", layout="wide")
st.title("ğŸ¦ Akbank Sanal Asistan (RAG Chatbot)")
st.caption("GenAI Bootcamp Projesi | Finansal SSS yanÄ±tlayÄ±cÄ±sÄ±")

# RAG bileÅŸenlerini yÃ¼kle
retriever, llm = load_rag_components()
rag_chain = create_rag_chain(retriever, llm)

# Sohbet geÃ§miÅŸi (AynÄ± kaldÄ±)
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant",
        "content": "Merhaba! Ben Akbank Sanal Asistan. Size finans ve bankacÄ±lÄ±k konularÄ±nda nasÄ±l yardÄ±mcÄ± olabilirim?"
    })

# Ã–nceki mesajlarÄ± gÃ¶ster (AynÄ± kaldÄ±)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ± giriÅŸi (AynÄ± kaldÄ±)
if prompt := st.chat_input("LÃ¼tfen sorunuzu buraya yazÄ±n..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± kaydet ve gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Chatbot yanÄ±tÄ±nÄ± Ã¼ret
    with st.chat_message("assistant"):
        with st.spinner("Cevap aranÄ±yor..."):
            try:
                response = rag_chain.invoke(prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                # Hata durumunda kullanÄ±cÄ±ya bilgi ver
                error_msg = f"ÃœzgÃ¼nÃ¼m, Gemini API'den yanÄ±t alÄ±nÄ±rken bir hata oluÅŸtu. LÃ¼tfen GOOGLE_API_KEY'inizin doÄŸru olduÄŸundan emin olun. Hata: {e}"
                st.markdown(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

# Sidebar (AynÄ± kaldÄ±)
st.sidebar.title("Product KÄ±lavuzu")
st.sidebar.markdown("""
**Test SenaryolarÄ±:**
- **Kredi kartÄ± baÅŸvurusu nasÄ±l yapÄ±lÄ±r?**
- **DÃ¶viz hesabÄ± aÃ§mak iÃ§in ne gerekiyor?**
- **Hesap iÅŸletim Ã¼creti alÄ±yor musunuz?**
- **DÃ¼nyanÄ±n en yÃ¼ksek daÄŸÄ± nedir?** (bilgim yok testi)
""")





